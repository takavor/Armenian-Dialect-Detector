{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true: save metrics to metrics folder\n",
    "SAVE_METRICS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the sentences from the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "western_sentences = []\n",
    "with open('data/western_sentences.txt', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        western_sentences.append(line)\n",
    "        \n",
    "eastern_sentences = []\n",
    "with open('data/eastern_sentences.txt', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        eastern_sentences.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strip newlines and join lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "western_sentences = [sentence.strip() for sentence in western_sentences]\n",
    "eastern_sentences = [sentence.strip() for sentence in eastern_sentences]\n",
    "sentences = western_sentences + eastern_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 if Western Armenian, 0 otherwise\n",
    "y = [1] * len(western_sentences) + [0] * len(eastern_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize sentences using character-level n-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_characters(sentences, n):\n",
    "    \n",
    "    tokenized_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        \n",
    "        sentence_tokens = []\n",
    "        \n",
    "        # sliding window of size n\n",
    "        for i in range(len(sentence) - (n - 1)):\n",
    "            \n",
    "            # extract and append n-gram\n",
    "            token = sentence[i:i+n]\n",
    "            sentence_tokens.append(token)\n",
    "        \n",
    "        tokenized_sentences.append(sentence_tokens)\n",
    "    \n",
    "    return tokenized_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation for learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature extraction using TF-IDF vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def get_tfidf_character_ngram_vectorizer(n):\n",
    "    return TfidfVectorizer(analyzer='char', ngram_range=(n, n)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_extracted_X(tokenized_sentences, vectorizer):\n",
    "    joined_tokens = [' '.join(tokens) for tokens in tokenized_sentences]\n",
    "    X = vectorizer.fit_transform(joined_tokens)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training learning models per character-level n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:02<00:00,  1.09it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm as tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# dictionary for metrics per n\n",
    "metrics_dict = {}\n",
    "\n",
    "# n values for ngrams\n",
    "ns = [3, 4, 5]\n",
    "\n",
    "for n in tqdm.tqdm(ns):\n",
    "    \n",
    "    # dictionary of metrics for current n\n",
    "    n_metrics = {}\n",
    "    \n",
    "    # tokenize sentences\n",
    "    tokenized_sentences = tokenize_characters(sentences, n=n)\n",
    "    \n",
    "    # get vectorizer\n",
    "    tfidf_vectorizer = get_tfidf_character_ngram_vectorizer(n=n)\n",
    "    \n",
    "    # get features\n",
    "    X = get_feature_extracted_X(tokenized_sentences=tokenized_sentences, vectorizer=tfidf_vectorizer)\n",
    "    \n",
    "    # train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "    \n",
    "    # models to train\n",
    "    lr = LogisticRegression(random_state=1)\n",
    "    nb = BernoulliNB()\n",
    "    dt = DecisionTreeClassifier(random_state=1)\n",
    "    svm = SVC(random_state=1)\n",
    "    \n",
    "    models = [('Logistic Regression', lr), ('Naive Bayes', nb), ('Decision Tree', dt), ('SVM', svm)]\n",
    "    \n",
    "    # initialize dictionary for metrics of each model\n",
    "    model_metrics = {model_name: {} for model_name, _ in models}\n",
    "\n",
    "    # fit models, obtain predictions and metrics    \n",
    "    for model_name, model in models:\n",
    "        \n",
    "        # fit model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # obtain predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "        # obtain metrics\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "        # store metrics\n",
    "        model_metrics[model_name]['Accuracy'] = acc\n",
    "        model_metrics[model_name]['F1'] = f1\n",
    "        model_metrics[model_name]['Precision'] = precision\n",
    "        model_metrics[model_name]['Recall'] = recall\n",
    "    \n",
    "    # store metrics for current n\n",
    "    n_metrics['Metrics'] = model_metrics\n",
    "    metrics_dict[n] = n_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract metrics and store to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# dataframe columns\n",
    "metrics_to_include = ['Accuracy', 'F1', 'Precision', 'Recall']\n",
    "\n",
    "# dictionary for dataframes per n value\n",
    "n_dataframes = {}\n",
    "\n",
    "for n, n_metrics in metrics_dict.items():\n",
    "    \n",
    "    # get metrics for current n\n",
    "    metrics_data = n_metrics['Metrics']\n",
    "    \n",
    "    # make dictionary to store data for dataframe\n",
    "    data_dict = {}\n",
    "    \n",
    "    # extract metrics to include\n",
    "    for metric in metrics_to_include:\n",
    "        metric_values = {model: metrics[metric] for model, metrics in metrics_data.items()}\n",
    "        # store metric\n",
    "        data_dict[metric] = metric_values\n",
    "    \n",
    "    # create dataframe for current n\n",
    "    n_df = pd.DataFrame(data_dict)\n",
    "    \n",
    "    # add dataframe to dictionary\n",
    "    n_dataframes[n] = n_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for $n=3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.904110</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.849315</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.939394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy        F1  Precision    Recall\n",
       "Logistic Regression  0.892857  0.916667   0.846154  1.000000\n",
       "Naive Bayes          0.875000  0.904110   0.825000  1.000000\n",
       "Decision Tree        0.803571  0.849315   0.775000  0.939394\n",
       "SVM                  0.892857  0.916667   0.846154  1.000000"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_dataframes[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for $n=4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.939394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy        F1  Precision    Recall\n",
       "Logistic Regression  0.857143  0.891892   0.804878  1.000000\n",
       "Naive Bayes          0.892857  0.916667   0.846154  1.000000\n",
       "Decision Tree        0.821429  0.861111   0.794872  0.939394\n",
       "SVM                  0.892857  0.916667   0.846154  1.000000"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_dataframes[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for $n=5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.849315</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.939394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy        F1  Precision    Recall\n",
       "Logistic Regression  0.785714  0.846154   0.733333  1.000000\n",
       "Naive Bayes          0.857143  0.891892   0.804878  1.000000\n",
       "Decision Tree        0.803571  0.849315   0.775000  0.939394\n",
       "SVM                  0.857143  0.891892   0.804878  1.000000"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_dataframes[5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

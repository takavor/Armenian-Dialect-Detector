{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true: save metrics to metrics folder\n",
    "SAVE_METRICS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the sentences from the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "western_sentences = []\n",
    "with open('../data/western_sentences.txt', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        western_sentences.append(line)\n",
    "        \n",
    "eastern_sentences = []\n",
    "with open('../data/eastern_sentences.txt', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        eastern_sentences.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strip newlines and join lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "western_sentences = [sentence.strip() for sentence in western_sentences]\n",
    "eastern_sentences = [sentence.strip() for sentence in eastern_sentences]\n",
    "sentences = western_sentences + eastern_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 if Western Armenian, 0 otherwise\n",
    "y = [1] * len(western_sentences) + [0] * len(eastern_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize sentences using character-level n-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_characters(sentences, n):\n",
    "    \n",
    "    tokenized_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        \n",
    "        sentence_tokens = []\n",
    "        \n",
    "        # sliding window of size n\n",
    "        for i in range(len(sentence) - (n - 1)):\n",
    "            \n",
    "            # extract and append n-gram\n",
    "            token = sentence[i:i+n]\n",
    "            sentence_tokens.append(token)\n",
    "        \n",
    "        tokenized_sentences.append(sentence_tokens)\n",
    "    \n",
    "    return tokenized_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation for learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature extraction using TF-IDF vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def get_tfidf_character_ngram_vectorizer(n):\n",
    "    return TfidfVectorizer(analyzer='char', ngram_range=(n, n)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_extracted_X(tokenized_sentences, vectorizer):\n",
    "    joined_tokens = [' '.join(tokens) for tokens in tokenized_sentences]\n",
    "    X = vectorizer.fit_transform(joined_tokens)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training learning models per character-level n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:30<00:00, 10.18s/it]\n"
     ]
    }
   ],
   "source": [
    "import tqdm as tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# dictionary for metrics per n\n",
    "metrics_dict = {}\n",
    "\n",
    "# n values for ngrams\n",
    "ns = [3, 4, 5]\n",
    "\n",
    "for n in tqdm.tqdm(ns):\n",
    "    \n",
    "    # dictionary of metrics for current n\n",
    "    n_metrics = {}\n",
    "    \n",
    "    # tokenize sentences\n",
    "    tokenized_sentences = tokenize_characters(sentences, n=n)\n",
    "    \n",
    "    # get vectorizer\n",
    "    tfidf_vectorizer = get_tfidf_character_ngram_vectorizer(n=n)\n",
    "    \n",
    "    # get features\n",
    "    X = get_feature_extracted_X(tokenized_sentences=tokenized_sentences, vectorizer=tfidf_vectorizer)\n",
    "    \n",
    "    # train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "    \n",
    "    # models to train\n",
    "    lr = LogisticRegression(random_state=1)\n",
    "    nb = BernoulliNB()\n",
    "    dt = DecisionTreeClassifier(random_state=1)\n",
    "    svm = SVC(random_state=1)\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(64, 32), random_state=1)\n",
    "    \n",
    "    models = [('Logistic Regression', lr), ('Naive Bayes', nb), ('Decision Tree', dt), ('SVM', svm), ('MLP', mlp)]\n",
    "    \n",
    "    # initialize dictionary for metrics of each model\n",
    "    model_metrics = {model_name: {} for model_name, _ in models}\n",
    "\n",
    "    # fit models, obtain predictions and metrics    \n",
    "    for model_name, model in models:\n",
    "        \n",
    "        # fit model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # obtain predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "        # obtain metrics\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "        # store metrics\n",
    "        model_metrics[model_name]['Accuracy'] = acc\n",
    "        model_metrics[model_name]['F1'] = f1\n",
    "        model_metrics[model_name]['Precision'] = precision\n",
    "        model_metrics[model_name]['Recall'] = recall\n",
    "    \n",
    "    # store metrics for current n\n",
    "    n_metrics['Metrics'] = model_metrics\n",
    "    metrics_dict[n] = n_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract metrics and store to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# dataframe columns\n",
    "metrics_to_include = ['Accuracy', 'F1', 'Precision', 'Recall']\n",
    "\n",
    "# dictionary for dataframes per n value\n",
    "n_dataframes = {}\n",
    "\n",
    "for n, n_metrics in metrics_dict.items():\n",
    "    \n",
    "    # get metrics for current n\n",
    "    metrics_data = n_metrics['Metrics']\n",
    "    \n",
    "    # make dictionary to store data for dataframe\n",
    "    data_dict = {}\n",
    "    \n",
    "    # extract metrics to include\n",
    "    for metric in metrics_to_include:\n",
    "        metric_values = {model: metrics[metric] for model, metrics in metrics_data.items()}\n",
    "        # store metric\n",
    "        data_dict[metric] = metric_values\n",
    "    \n",
    "    # create dataframe for current n\n",
    "    n_df = pd.DataFrame(data_dict)\n",
    "    \n",
    "    # add dataframe to dictionary\n",
    "    n_dataframes[n] = n_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for $n=3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.90625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.96875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy        F1  Precision   Recall\n",
       "Logistic Regression  0.979592  0.984615   0.969697  1.00000\n",
       "Naive Bayes          0.918367  0.935484   0.966667  0.90625\n",
       "Decision Tree        0.938776  0.953846   0.939394  0.96875\n",
       "SVM                  0.979592  0.984615   0.969697  1.00000\n",
       "MLP                  0.979592  0.984615   0.969697  1.00000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_dataframes[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for $n=4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.96875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy        F1  Precision   Recall\n",
       "Logistic Regression  0.979592  0.984615   0.969697  1.00000\n",
       "Naive Bayes          0.979592  0.984615   0.969697  1.00000\n",
       "Decision Tree        0.938776  0.953846   0.939394  0.96875\n",
       "SVM                  0.979592  0.984615   0.969697  1.00000\n",
       "MLP                  0.979592  0.984615   0.969697  1.00000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_dataframes[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for $n=5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.96875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy        F1  Precision   Recall\n",
       "Logistic Regression  0.959184  0.969697   0.941176  1.00000\n",
       "Naive Bayes          0.979592  0.984615   0.969697  1.00000\n",
       "Decision Tree        0.959184  0.968750   0.968750  0.96875\n",
       "SVM                  0.959184  0.969697   0.941176  1.00000\n",
       "MLP                  0.979592  0.984615   0.969697  1.00000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_dataframes[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_METRICS:\n",
    "    \n",
    "    # create list of dataframes\n",
    "    df_list = [n_dataframes[n] for n in ns]\n",
    "    \n",
    "    for n in ns:\n",
    "        n_dataframes[n].to_csv(f'../metrics/{n}gram.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
